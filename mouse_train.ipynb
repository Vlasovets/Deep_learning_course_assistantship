{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mouse_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlasovets/Deep_learning_course_assistantship/blob/master/mouse_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvVvsTNFV22W",
        "colab_type": "text"
      },
      "source": [
        "# Advanced topics in User Interfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pneyo9ERWBNc",
        "colab_type": "text"
      },
      "source": [
        "## **Learning goals** \n",
        "The tutorial covers the topics explained during the lecture in the following parts:\n",
        "1.   to get introduced with common deep learning models (e.g. LSTM)\n",
        "2.   to understand the pipeline of a model creation in TensorFlow\n",
        "3.   to train and test models on given datasets\n",
        "4.   to work with different paramters of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQnyC8tMWZl1",
        "colab_type": "text"
      },
      "source": [
        "## 1 Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxqk1e5qXv75",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Mouse movement \n",
        "Machine learning became critical for marketers and advertisers, who need to analyze endless signals in real time and deliver ads at the right moments to the right people. Many researchers have focused on identifying whether a series of actions were performed by humans or bots. It is a very applied research area since people tend to use online shopping more and the location of advertisement makes a difference for the company. \n",
        "\n",
        "**Example**\n",
        "\n",
        "By adding a properly placed ads on the website, a company could see directly what users’ preferences are. On top of insights about users preferences the company would also get information about the people who are actually interested in their products.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs3Nw0NDea4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ba2e2d65-b97a-4eca-a748-f4890a8ce46b"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://image.winudf.com/v2/image/Y29tLnRodW5rYWJsZS5hbmRyb2lkLm9mZmljaWFsYXBwNDYxOC5Nb25leV9NYWtlcl9pY29uXzE1MTQzNDk2OTZfMDEy/icon.png?w=170&fakeurl=1\", width=200, height=200)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://image.winudf.com/v2/image/Y29tLnRodW5rYWJsZS5hbmRyb2lkLm9mZmljaWFsYXBwNDYxOC5Nb25leV9NYWtlcl9pY29uXzE1MTQzNDk2OTZfMDEy/icon.png?w=170&fakeurl=1\" width=\"200\" height=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnaNrcNufCVE",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Dataset\n",
        "This tutorial provides a glimpse of how the data from mouse movements can be used. It contains following information:\n",
        "\n",
        "\n",
        "*   User ID\n",
        "*   View point width\n",
        "*   View point height\n",
        "*   Age\n",
        "*   Movements\n",
        "\n",
        "*Please,add some details about the dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6E5XWqhf76J",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA6Qrt7cp-vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fc478bba-4143-405b-f2fb-bcc95d5a5eb2"
      },
      "source": [
        "%tensorflow_version 1.x # complementary code"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x # complementary code`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU9rDWIemPBH",
        "colab_type": "text"
      },
      "source": [
        "Make sure that you use the right version of TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDTwfmZJ7Ykr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "39954e6b-9c39-4d01-a553-eb06b80efaac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # complementary code"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I04bMYSlmU5o",
        "colab_type": "text"
      },
      "source": [
        "Do not forget to upload the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-HcguRZ3bPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential, save_model\n",
        "from tensorflow.python.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz_Dwie7iwir",
        "colab_type": "text"
      },
      "source": [
        "Import all necessary libraries and set a configuration for the following model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahDlGmwl3eL0",
        "colab_type": "code",
        "outputId": "7bff085f-85ad-4834-ce1e-14c123a3be0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Some GPUs require setting the `allow_growth` setting.\n",
        "# Comment out this code is you don't have a GPU card.\n",
        "import tensorflow.compat.v1 as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.Session(config=config)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f46304eb898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz2duGIgPr4i",
        "colab_type": "text"
      },
      "source": [
        "### 2. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCTO71hTi5Y0",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyo9IXjjHqO",
        "colab_type": "text"
      },
      "source": [
        "Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect, incomplete or improperly formatted. \n",
        "\n",
        "It is very a rare case in a real life when data provided is clean and does not require additional manipulation. So, the 80% of the typical workload for a person working with data is preparing the data for an actual analysis.\n",
        "There are several methods for cleaning data depending, here you see the following steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smPTPh9l3fxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(filename):\n",
        "    X, y = [], []\n",
        "    with open(filename) as csv_file:\n",
        "        csv_reader = csv.DictReader(csv_file, delimiter='\\t')\n",
        "        for row in csv_reader:\n",
        "            moves = parse_moves(row['movements'])\n",
        "            age = parse_age(row['age'])\n",
        "            X.append(moves)\n",
        "            y.append(age)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqHkLLEtj-4h",
        "colab_type": "text"
      },
      "source": [
        "'Def' declares a function with a name 'load_dataset' and the parameter 'filename', more [info](https://wiki.python.org/moin/BeginnersGuide) . Then the 'for loop' load the data with the headings we need. Finally, we create [np.array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html) for our depending (X) and target (y) variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnt4K-y3kPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_moves(seq):\n",
        "    result = []\n",
        "    coords = seq.split(',')\n",
        "    for coord in coords:\n",
        "        x, y, t = coord.split(';')\n",
        "        result.append([int(x), int(y)])\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3x0ugNp3oAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_age(age):\n",
        "    if age == 'young':\n",
        "        return 0\n",
        "    elif age == 'adult':\n",
        "        return 1\n",
        "    elif age == 'elder':\n",
        "        return 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62XbvMlDlgAu",
        "colab_type": "text"
      },
      "source": [
        "Functions 'parse_moves' and 'parse_age' are used for separating the moves by three age groups: \n",
        "\n",
        "\n",
        "*   young\n",
        "*   adult\n",
        "*   elder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7Q0_453qGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(shape):\n",
        "    units = shape[0]\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units), input_shape=shape))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi2EnRq0l8l1",
        "colab_type": "text"
      },
      "source": [
        "Finally, we create our BiLSTM model. The idea of the model is straightforward. It involves duplicating the first recurrent layer in the network so that there are now two layers side-by-side, then providing the input sequence as-is as input to the first layer and providing a reversed copy of the input sequence to the second. It uses sofmax function as an activation function, sparse categorical crossentropy as a loss function. \n",
        "\n",
        "For evaluation purpose we pick metric accuracy.\n",
        "It is the ratio of number of correct predictions to the total number of input samples. It works well if there are equal number of samples belonging to each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPSQFCQp30IK",
        "colab_type": "code",
        "outputId": "8e8fb6ea-75f7-4052-90ac-a4ff985a9116",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files # complementary code\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ad83ac1-06b1-4456-b2c0-d69cba742317\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9ad83ac1-06b1-4456-b2c0-d69cba742317\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mousemoves.csv to mousemoves (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMsTltBxC1Ps",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Model training\n",
        "**How to Train Deep Learning Models?**\n",
        "\n",
        "It might seem like it took us a while to get here, but professional data scientists actually spend the bulk of their time on the steps leading up to this one:\n",
        "* Exploring the data.\n",
        "* Cleaning the data.\n",
        "* Engineering new features.\n",
        "\n",
        "Again, that’s because better data beats fancier algorithms.\n",
        "\n",
        "Now, we have finished the steps above and ready to fit the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUMrKIQo3su4",
        "colab_type": "code",
        "outputId": "693f7a94-6688-4961-d635-f1448b8bd40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # The saved model file will be named like the dataset file.\n",
        "    dataset_file = 'mousemoves.csv'\n",
        "\n",
        "    X, y = load_dataset(dataset_file)\n",
        "\n",
        "    # All sequences must have the same length.\n",
        "    X = pad_sequences(X)\n",
        "\n",
        "    # Create partitions.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "    # Set callbacks, for monitoring progress.\n",
        "    cb_tensorboard = TensorBoard(log_dir='/tmp/mouse_logs')\n",
        "    cb_earlystopping = EarlyStopping(patience=10)\n",
        "    cb_checkpoint = ModelCheckpoint('/tmp/mouse_logs/best.h5', save_best_only=True)\n",
        "\n",
        "    # Train the model.\n",
        "    model = create_model(X_train[0].shape)\n",
        "    print(model.summary())\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,\n",
        "        callbacks=[cb_tensorboard, cb_earlystopping, cb_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model.\n",
        "    loss, acc = model.evaluate(X_test, y_test)\n",
        "    print('ACC: {:.2f}'.format(acc))\n",
        "\n",
        "    # Save the model.\n",
        "    save_model(model, '{}.h5'.format(dataset_file))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 444)               399600    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 444)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 1335      \n",
            "=================================================================\n",
            "Total params: 400,935\n",
            "Trainable params: 400,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 204 samples, validate on 51 samples\n",
            "Epoch 1/100\n",
            "204/204 [==============================] - 8s 38ms/sample - loss: 1.1981 - acc: 0.3627 - val_loss: 1.1168 - val_acc: 0.3725\n",
            "Epoch 2/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.1403 - acc: 0.3725 - val_loss: 1.0868 - val_acc: 0.3725\n",
            "Epoch 3/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.1133 - acc: 0.4265 - val_loss: 1.1074 - val_acc: 0.4118\n",
            "Epoch 4/100\n",
            "204/204 [==============================] - 6s 28ms/sample - loss: 1.1256 - acc: 0.3578 - val_loss: 1.1157 - val_acc: 0.4118\n",
            "Epoch 5/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.1362 - acc: 0.3922 - val_loss: 1.1192 - val_acc: 0.3725\n",
            "Epoch 6/100\n",
            "204/204 [==============================] - 6s 28ms/sample - loss: 1.0585 - acc: 0.4265 - val_loss: 1.1100 - val_acc: 0.3137\n",
            "Epoch 7/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0945 - acc: 0.3971 - val_loss: 1.0995 - val_acc: 0.4118\n",
            "Epoch 8/100\n",
            "204/204 [==============================] - 6s 28ms/sample - loss: 1.0522 - acc: 0.4706 - val_loss: 1.1043 - val_acc: 0.3725\n",
            "Epoch 9/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0848 - acc: 0.3971 - val_loss: 1.1123 - val_acc: 0.3137\n",
            "Epoch 10/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0752 - acc: 0.4167 - val_loss: 1.1229 - val_acc: 0.2941\n",
            "Epoch 11/100\n",
            "204/204 [==============================] - 6s 28ms/sample - loss: 1.0539 - acc: 0.4706 - val_loss: 1.1149 - val_acc: 0.3529\n",
            "Epoch 12/100\n",
            "204/204 [==============================] - 6s 28ms/sample - loss: 1.0813 - acc: 0.4657 - val_loss: 1.1199 - val_acc: 0.3922\n",
            "51/51 [==============================] - 0s 7ms/sample - loss: 1.1199 - acc: 0.3922\n",
            "ACC: 0.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6SEafjJNyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "386abd52-1ce6-471b-aa2e-11ce2834b5c7"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://miro.medium.com/max/1024/1*cDhZ56QNC5mrl6kjE0C2JA.png\", width=500, height=350)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/1024/1*cDhZ56QNC5mrl6kjE0C2JA.png\" width=\"500\" height=\"350\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7kU2-91GH9u",
        "colab_type": "text"
      },
      "source": [
        "You might guess what is 'an epoch' in the output?\n",
        "\n",
        "In deep learning an epoch is a [hyperparameter](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) which is defined before training a model. In other words, one epoch is when an entire dataset is passed both forward and backward through the neural network only once.\n",
        "\n",
        "The reason why we have to split the training step by epochs is decrease the amount of data we feed to the computer at once. So, we divide it in several smaller batches. We use more than one epoch because passing the entire dataset through a neural network is not enough and we need to pass the full dataset multiple times to the same neural network. But since we are using a limited dataset we can do it in an iterative process. A batch is the total number of training examples present in a single batch and an iteration is the number of batches needed to complete one epoch.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "If we divide a dataset of 2000 training examples into 500 batches, then 4 iterations will complete 1 epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWFLWJvcnWZn",
        "colab_type": "text"
      },
      "source": [
        "**Our result for training**:\n",
        "\n",
        "The training on 204 traning and 51 validation samples finished with accuracy 0.37 which is very low. If we guess, it can be explained by a huge amount of noise in the data.  You can read about how to tune the model and increase the accurucy [here](https://www.kdnuggets.com/2019/01/fine-tune-machine-learning-models-forecasting.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DayhrggTFAUF",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Model testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hUozabBKV2D",
        "colab_type": "text"
      },
      "source": [
        "Once we trained our model we would like to understand how does is work on a real data. We assume that the test dataset is a real data to evaluate our model. The reason behind this manipulation is simple - we would like to understand if we are overfitting or not. [Overfitting](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/) refers to a model that models the training data too well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ZlnFiPFWS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "471b7a1b-41be-424d-801f-8e18b1fed76a"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "#unncomment the next line you your model is stored in the separate file\n",
        "#from mouse_train import load_dataset\n",
        "\n",
        "# Some GPUs require setting the `allow_growth` setting.\n",
        "# Comment out this code is you don't have a GPU card.\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.Session(config=config)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f45e5775940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7W0IWBsFKRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8faa5580-3a52-44a2-8b98-86676c75dac2"
      },
      "source": [
        "dataset_file = 'mousemoves.csv'\n",
        "\n",
        "X, y = load_dataset(dataset_file)\n",
        "\n",
        "# All sequences must have the same length.\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Create partitions.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "# Don't compile the model when testing new data.\n",
        "model = load_model('{}.h5'.format(dataset_file), compile=False)\n",
        "probs = model.predict(X_test)\n",
        "y_pred = [np.argmax(x) for x in probs]\n",
        "\n",
        "# Let's see how good those predictions were.\n",
        "precision, recall, fmeasure, _ = precision_recall_fscore_support(y_test, y_pred, pos_label=None, average='weighted')\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F-measure: {:.2f}%'.format(fmeasure * 100))\n",
        "\n",
        "# Finally compute the ROC AUC to see the discriminative power of the model.\n",
        "binary_labels = [p == y_test[i] for i, p in enumerate(y_pred)]\n",
        "y_probs = [x.max() for x in probs]\n",
        "auc = roc_auc_score(binary_labels, y_probs, average='weighted')\n",
        "print('AUC: {:.2f}%'.format(auc * 100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 50.28%\n",
            "Recall: 49.02%\n",
            "F-measure: 49.13%\n",
            "AUC: 47.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWsVg98rL5dE",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. Results\n",
        "The output of the last cell gives us 4 different metrics for our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCdstgaOMPPe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Precision** and **recall** are two extremely important model evaluation metrics. While precision refers to the percentage of your results which are relevant, recall refers to the percentage of total relevant results correctly classified by your algorithm. Unfortunately, it is not possible to maximize both these metrics at the same time, as one comes at the cost of another. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lczIIW25MuNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "8375f6a3-1d3d-4f79-d1da-81eeff4ef431"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML\n",
        "Image(url= \"https://miro.medium.com/max/1068/1*EXa-_699fntpUoRjZeqAFQ.jpeg\", width=400, height=150)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/1068/1*EXa-_699fntpUoRjZeqAFQ.jpeg\" width=\"400\" height=\"150\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wp3ZQf-NftL",
        "colab_type": "text"
      },
      "source": [
        "For simplicity, there is another metric available, called F-1 score, which is a harmonic mean of precision and recall. One can select a model which maximizes this F-1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKGPQr9sQBJ9",
        "colab_type": "text"
      },
      "source": [
        "## 3 Conclusion\n",
        "\n",
        "Now, you know:\n",
        "\n",
        "1.   a common deep learning model\n",
        "2.   a general pipeline of a model creation in TensorFlow\n",
        "3.   to work with different paramters of the model\n",
        "4.   a commonly used application of deep learning\n",
        "\n",
        "Do not hesitate to ask questions at otorrent@mail.ru\n",
        "\n",
        "Thank you for your attention and see you next exercise session!"
      ]
    }
  ]
}