{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mouse_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlasovets/Deep_learning_course_assistantship/blob/master/mouse_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvVvsTNFV22W",
        "colab_type": "text"
      },
      "source": [
        "# Advanced topics in User Interfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pneyo9ERWBNc",
        "colab_type": "text"
      },
      "source": [
        "## **Learning goals** \n",
        "The tutorial covers the topics explained during the lecture in the following parts:\n",
        "1.   to get introduced with common deep learning models (e.g. LSTM)\n",
        "2.   to understand the pipeline of a model creation in TensorFlow\n",
        "3.   to train and test models on given datasets\n",
        "4.   to work with different paramters of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQnyC8tMWZl1",
        "colab_type": "text"
      },
      "source": [
        "## 1 Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxqk1e5qXv75",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Mouse movement \n",
        "Machine learning became critical for marketers and advertisers, who need to analyze endless signals in real time and deliver ads at the right moments to the right people. Many researchers have focused on identifying whether a series of actions were performed by humans or bots. It is a very applied research area since people tend to use online shopping more and the location of advertisement makes a difference for the company. \n",
        "\n",
        "**Example**\n",
        "\n",
        "By adding a properly placed ads on the website, a company could see directly what users’ preferences are. On top of insights about users preferences the company would also get information about the people who are actually interested in their products.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs3Nw0NDea4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8d90e724-27c1-4930-a73f-2e50e30380fd"
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://image.winudf.com/v2/image/Y29tLnRodW5rYWJsZS5hbmRyb2lkLm9mZmljaWFsYXBwNDYxOC5Nb25leV9NYWtlcl9pY29uXzE1MTQzNDk2OTZfMDEy/icon.png?w=170&fakeurl=1\", width=200, height=200)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://image.winudf.com/v2/image/Y29tLnRodW5rYWJsZS5hbmRyb2lkLm9mZmljaWFsYXBwNDYxOC5Nb25leV9NYWtlcl9pY29uXzE1MTQzNDk2OTZfMDEy/icon.png?w=170&fakeurl=1\" width=\"200\" height=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnaNrcNufCVE",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Dataset\n",
        "This tutorial provides a glimpse of how the data from mouse movements can be used. It contains following information:\n",
        "\n",
        "\n",
        "*   User ID\n",
        "*   View point width\n",
        "*   View point height\n",
        "*   Age\n",
        "*   Movements\n",
        "\n",
        "*Please,add some details about the dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6E5XWqhf76J",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA6Qrt7cp-vq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "bc1d2b97-d4e2-47e4-870b-5f79fb60f6ce"
      },
      "source": [
        "%tensorflow_version 1.x # complementary code"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x # complementary code`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU9rDWIemPBH",
        "colab_type": "text"
      },
      "source": [
        "Make sure that you use the right version of TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDTwfmZJ7Ykr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "28ee6c6e-7d8c-4889-fae1-2e1c17fbd038"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # complementary code"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I04bMYSlmU5o",
        "colab_type": "text"
      },
      "source": [
        "Do not forget to upload the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-HcguRZ3bPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.models import Sequential, save_model\n",
        "from tensorflow.python.keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz_Dwie7iwir",
        "colab_type": "text"
      },
      "source": [
        "Import all necessary libraries and set a configuration for the following model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahDlGmwl3eL0",
        "colab_type": "code",
        "outputId": "90406f10-d4fe-430a-b68f-9c6697cb9d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Some GPUs require setting the `allow_growth` setting.\n",
        "# Comment out this code is you don't have a GPU card.\n",
        "import tensorflow.compat.v1 as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.Session(config=config)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f4680dc07f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCTO71hTi5Y0",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyo9IXjjHqO",
        "colab_type": "text"
      },
      "source": [
        "Data cleaning is the process of preparing data for analysis by removing or modifying data that is incorrect, incomplete or improperly formatted. \n",
        "\n",
        "It is very a rare case in a real life when data provided is clean and does not require additional manipulation. So, the 80% of the typical workload for a person working with data is preparing the data for an actual analysis.\n",
        "There are several methods for cleaning data depending, here you see the following steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smPTPh9l3fxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(filename):\n",
        "    X, y = [], []\n",
        "    with open(filename) as csv_file:\n",
        "        csv_reader = csv.DictReader(csv_file, delimiter='\\t')\n",
        "        for row in csv_reader:\n",
        "            moves = parse_moves(row['movements'])\n",
        "            age = parse_age(row['age'])\n",
        "            X.append(moves)\n",
        "            y.append(age)\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqHkLLEtj-4h",
        "colab_type": "text"
      },
      "source": [
        "'Def' declares a function with a name 'load_dataset' and the parameter 'filename', more [info](https://wiki.python.org/moin/BeginnersGuide) . Then the 'for loop' load the data with the headings we need. Finally, we create [np.array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html) for our depending (X) and target (y) variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDnt4K-y3kPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_moves(seq):\n",
        "    result = []\n",
        "    coords = seq.split(',')\n",
        "    for coord in coords:\n",
        "        x, y, t = coord.split(';')\n",
        "        result.append([int(x), int(y)])\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3x0ugNp3oAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_age(age):\n",
        "    if age == 'young':\n",
        "        return 0\n",
        "    elif age == 'adult':\n",
        "        return 1\n",
        "    elif age == 'elder':\n",
        "        return 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62XbvMlDlgAu",
        "colab_type": "text"
      },
      "source": [
        "Functions 'parse_moves' and 'parse_age' are used for separating the moves by three age groups: \n",
        "\n",
        "\n",
        "*   young\n",
        "*   adult\n",
        "*   elder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7Q0_453qGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(shape):\n",
        "    units = shape[0]\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units), input_shape=shape))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi2EnRq0l8l1",
        "colab_type": "text"
      },
      "source": [
        "Finally, we create our BiLSTM model. The idea of the model is straightforward. It involves duplicating the first recurrent layer in the network so that there are now two layers side-by-side, then providing the input sequence as-is as input to the first layer and providing a reversed copy of the input sequence to the second. It uses sofmax function as an activation function, sparse categorical crossentropy as a loss function. \n",
        "\n",
        "For evaluation purpose we pick metric accuracy.\n",
        "It is the ratio of number of correct predictions to the total number of input samples. It works well if there are equal number of samples belonging to each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPSQFCQp30IK",
        "colab_type": "code",
        "outputId": "042b14fe-207a-4036-e417-cffec3096c98",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files # Oleg's code\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a70dbfd-3b29-4892-92e4-63a6b3ac50c4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5a70dbfd-3b29-4892-92e4-63a6b3ac50c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mousemoves.csv to mousemoves (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUMrKIQo3su4",
        "colab_type": "code",
        "outputId": "cd0a5b4a-febb-4609-aa18-e45ca8b6ff05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # The saved model file will be named like the dataset file.\n",
        "    dataset_file = 'mousemoves.csv'\n",
        "\n",
        "    X, y = load_dataset(dataset_file)\n",
        "\n",
        "    # All sequences must have the same length.\n",
        "    X = pad_sequences(X)\n",
        "\n",
        "    # Create partitions.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
        "\n",
        "    # Set callbacks, for monitoring progress.\n",
        "    cb_tensorboard = TensorBoard(log_dir='/tmp/mouse_logs')\n",
        "    cb_earlystopping = EarlyStopping(patience=10)\n",
        "    cb_checkpoint = ModelCheckpoint('/tmp/mouse_logs/best.h5', save_best_only=True)\n",
        "\n",
        "    # Train the model.\n",
        "    model = create_model(X_train[0].shape)\n",
        "    print(model.summary())\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,\n",
        "        callbacks=[cb_tensorboard, cb_earlystopping, cb_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model.\n",
        "    loss, acc = model.evaluate(X_test, y_test)\n",
        "    print('ACC: {:.2f}'.format(acc))\n",
        "\n",
        "    # Save the model.\n",
        "    save_model(model, '{}.h5'.format(dataset_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_3 (Bidirection (None, 444)               399600    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 444)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1335      \n",
            "=================================================================\n",
            "Total params: 400,935\n",
            "Trainable params: 400,935\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 204 samples, validate on 51 samples\n",
            "Epoch 1/100\n",
            "204/204 [==============================] - 9s 45ms/sample - loss: 1.2412 - acc: 0.2990 - val_loss: 1.1029 - val_acc: 0.3529\n",
            "Epoch 2/100\n",
            "204/204 [==============================] - 6s 31ms/sample - loss: 1.1536 - acc: 0.3627 - val_loss: 1.1036 - val_acc: 0.3922\n",
            "Epoch 3/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.1246 - acc: 0.3480 - val_loss: 1.0879 - val_acc: 0.3922\n",
            "Epoch 4/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.1174 - acc: 0.4265 - val_loss: 1.1025 - val_acc: 0.3529\n",
            "Epoch 5/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.1398 - acc: 0.4069 - val_loss: 1.1152 - val_acc: 0.3725\n",
            "Epoch 6/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.1015 - acc: 0.4363 - val_loss: 1.1305 - val_acc: 0.2941\n",
            "Epoch 7/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0515 - acc: 0.4265 - val_loss: 1.1182 - val_acc: 0.2549\n",
            "Epoch 8/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.0701 - acc: 0.4314 - val_loss: 1.1016 - val_acc: 0.2941\n",
            "Epoch 9/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0673 - acc: 0.4118 - val_loss: 1.0901 - val_acc: 0.3922\n",
            "Epoch 10/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.0774 - acc: 0.4804 - val_loss: 1.0949 - val_acc: 0.4314\n",
            "Epoch 11/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.0640 - acc: 0.4265 - val_loss: 1.0977 - val_acc: 0.3725\n",
            "Epoch 12/100\n",
            "204/204 [==============================] - 6s 30ms/sample - loss: 1.0525 - acc: 0.4510 - val_loss: 1.0971 - val_acc: 0.4314\n",
            "Epoch 13/100\n",
            "204/204 [==============================] - 6s 29ms/sample - loss: 1.0498 - acc: 0.4902 - val_loss: 1.0885 - val_acc: 0.3725\n",
            "51/51 [==============================] - 0s 8ms/sample - loss: 1.0885 - acc: 0.3725\n",
            "ACC: 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWFLWJvcnWZn",
        "colab_type": "text"
      },
      "source": [
        "The training finished with accuracy 0.37 which is very low. If we guess, it can be explained by a huge amount of noise in the data."
      ]
    }
  ]
}