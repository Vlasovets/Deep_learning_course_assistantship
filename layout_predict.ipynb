{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "layout_predict.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlasovets/Deep_learning_course_assistantship/blob/master/layout_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNLIx3qvh2eP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "869e4cd1-8fcc-4c93-cf08-1e7b9d4af5d0"
      },
      "source": [
        "%tensorflow_version 1.x # Oleg's code"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x # Oleg's code`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pnlkLhY1p73",
        "colab_type": "code",
        "outputId": "8f8125a9-0a3a-4b2d-a197-fa705dd00ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "# Some GPUs require setting the `allow_growth` setting.\n",
        "# Comment out this code is you don't have a GPU card.\n",
        "import tensorflow.compat.v1 as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.Session(config=config)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f1814c6a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfmJPDqBiAEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip layouts-easy.zip #Oleg unzips the folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX-GNsyJ12q_",
        "colab_type": "code",
        "outputId": "b8a9afdb-2cb2-490d-d0e9-cacd541a0465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset_dir = 'layouts-easy'\n",
        "trainer_dir = dataset_dir + '/train'\n",
        "\n",
        "# Specify manually the class labels, otherwise Keras will assign alphanumeric values\n",
        "# as directories are listed (in no particular order).\n",
        "dirname, class_labels, _ = next(os.walk(trainer_dir))\n",
        "print('Class labels: {}'.format(class_labels))\n",
        "\n",
        "# Don't compile the model when testing new data.\n",
        "# model = load_model('{}.h5'.format(dataset_dir), compile=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class labels: ['Good', 'Bad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP8SLEPek1vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('{}.h5'.format(dataset_dir), compile=False) #Oleg compile the trained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOpP4FzQ2U6F",
        "colab_type": "code",
        "outputId": "9089ea4d-5261-4da2-b7bd-d1aa947590a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Don't shuffle the data, so that we can get the groundtruth labels later.\n",
        "test_generator = ImageDataGenerator().flow_from_directory(\n",
        "    dataset_dir + '/test',\n",
        "    shuffle=False,\n",
        "    color_mode='grayscale',\n",
        "    target_size=(200, 200),\n",
        "    class_mode='binary',\n",
        "    classes=class_labels\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQReZpDE2dYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since we have groundtruth labels, we can use `model.evaluate_generator` here.\n",
        "# However in production we don't have groundtruth so let's use the model to predict new data\n",
        "# and then compare the predictions against the test labels.\n",
        "y_true = list(map(lambda f : os.path.dirname(f), test_generator.filenames))\n",
        "probas = model.predict_generator(test_generator)\n",
        "y_pred = list(map(lambda p : class_labels[0] if p < 0.5 else class_labels[1], probas))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rKiONUF2eQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "59c2c07c-6993-4558-da72-274a5406d04c"
      },
      "source": [
        "# Let's see how good those predictions were.\n",
        "precision, recall, fmeasure, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_labels, average='weighted')\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F-measure: {:.2f}%'.format(fmeasure * 100))\n",
        "\n",
        "# Finally compute the ROC AUC to see the discriminative power of the model.\n",
        "# We'll use the `roc_auc_score()` function, which expects *binary* groundtruth labels and probability estimates of the *positive class*;\n",
        "# so be careful how labels and probabilities are defined.\n",
        "binary_labels = [p == y_true[i] for i, p in enumerate(y_pred)]\n",
        "auc = roc_auc_score(binary_labels, 1 - probas, average='weighted')\n",
        "print('AUC: {:.2f}%'.format(auc * 100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 77.10%\n",
            "Recall: 66.00%\n",
            "F-measure: 62.12%\n",
            "AUC: 60.56%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}