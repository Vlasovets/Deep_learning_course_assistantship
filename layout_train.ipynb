{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "layout_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlasovets/Deep_learning_course_assistantship/blob/master/layout_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u06VXbls6pxu",
        "colab_type": "text"
      },
      "source": [
        "# Advanced topics in User Interfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5yuurMN6xc8",
        "colab_type": "text"
      },
      "source": [
        "## **Learning goals** \n",
        "The tutorial covers the topics explained during the lecture in the following parts:\n",
        "1.   to get introduced to the image recognition model and how it can be applied to website layouts.\n",
        "2.   to get introduced to generators in Python\n",
        "3.   to train and test models on given datasets\n",
        "4.   to get introduced to ReLU activation function "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIHorF-c7FDZ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSm2bLrs7Jxr",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Layout composition \n",
        "A website layout is a pattern that defines a website’s structure. It has the role of structuring the information present on a site both for the website’s owner and for users. It provides clear paths for navigation within webpages and puts the most important elements of a website front and center.\n",
        "\n",
        "There are many reasons to consider a choice of layout wisely, for example:\n",
        "- A good layout keeps users on the site because it makes important information easily accessible and intuitive to find. A bad layout frustrates users which then quickly leaves the site because they can’t find what they are looking for.\n",
        "\n",
        "- There’s a strong [relationship](https://blog.hubspot.com/marketing/compelling-stats-website-design-optimization-list) between the layout and the engagement of users with the website. It determines how long they dwell on the website pages, how many pages they browse and how often they come back to the website.\n",
        "\n",
        "- According to Adobe research, 38% of people will stop engaging with a website if the content/layout is unattractive.\n",
        "\n",
        "You can think about other reasons why layouts are important. Once you have no doubts, you can start the following exercise.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNza7yvgSxSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x # this tutorial use TensorFlow v.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtzd8349GEWi",
        "colab_type": "text"
      },
      "source": [
        "Importing necessary libraries for this tutorial.\n",
        "\n",
        "If you face the error \"No module found:...\", make sure that prerequisites from the first exercise session are satisfied and you installed all the packages we use.\n",
        "\n",
        "*Hint: use the following command to install the package\n",
        "```\n",
        "# !pip install #packagename\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCrbEFx2ph2",
        "colab_type": "code",
        "outputId": "baa0d48a-1f8d-4408-afe4-5d724234e6a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.models import Sequential #The Sequential model is a linear stack of layers\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Some GPUs require setting the `allow_growth` setting.\n",
        "# Comment out this code is you don't have a GPU card.\n",
        "import tensorflow.compat.v1 as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "tf.Session(config=config)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f94ec31a2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwGic1BFhJZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip layouts-easy.zip #complementary code for loading the data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlsjnUhn-qGY",
        "colab_type": "text"
      },
      "source": [
        "## 2. Dataset description\n",
        "The data for today's exericise session is a number of layouts which can be categorized into two groups:\n",
        "- <font color=green>good</font> cop (layout)\n",
        "- <font color=red>bad</font> cop (layout)\n",
        "\n",
        "The distinction is based on the composition of the layout.\n",
        "\n",
        "\n",
        "*Please, add some details about the dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNlb9JEWBiAl",
        "colab_type": "text"
      },
      "source": [
        "### **Bad layout 😭**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y05dyKxF_W8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "aa0fcdca-a0ff-49c3-e350-3a1e08deddb0"
      },
      "source": [
        "from IPython.display import HTML\n",
        "HTML('<img src=\"https://media.giphy.com/media/IhgEVrZZ2p8g5g3pFh/giphy.gif\">')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://media.giphy.com/media/IhgEVrZZ2p8g5g3pFh/giphy.gif\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqezLkVsBoK8",
        "colab_type": "text"
      },
      "source": [
        "### **Good Layout😀**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lchEZ4ivB02f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "1e66828f-5309-4465-cc22-fcf77ce19eb7"
      },
      "source": [
        "HTML('<img src=\"https://media.giphy.com/media/lSE2LCTTrae4GEy4Km/giphy.gif\">')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://media.giphy.com/media/lSE2LCTTrae4GEy4Km/giphy.gif\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AppRHHNCHl6B",
        "colab_type": "text"
      },
      "source": [
        "The following code assigns the hyperparameters such as the number of epochs and the batch size. The choice of these hyperparameters affects the accuracy and the training time of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0_FV4Ls2vnH",
        "colab_type": "code",
        "outputId": "d5368c13-76e0-494d-e411-221659e910d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "IMAGE_SIZE = (200, 200)\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "dataset_dir = 'layouts-easy'\n",
        "trainer_dir = dataset_dir + '/train'\n",
        "\n",
        "# Specify manually the class labels, otherwise Keras will assign alphanumeric values\n",
        "# as directories are listed (in no particular order).\n",
        "dirname, class_labels, _ = next(os.walk(trainer_dir))\n",
        "print('Class labels: {}'.format(class_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class labels: ['Good', 'Bad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ek__v4kIdk0",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data.\n",
        "\n",
        "Basic augmentation techniques are commonly used to train large neural networks:\n",
        "- cropping\n",
        "- padding\n",
        "- horizontal flipping\n",
        "\n",
        "More info on data augmentation can be found [here](https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5hlRVRy2-B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply some data augmentation techniques.\n",
        "image_data = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0txis1gJOCs",
        "colab_type": "text"
      },
      "source": [
        "*Python Note*🤓\n",
        "\n",
        "In the next cell we use <font color=yellow>*generators*</font> - simple functions which return an iterable set of items, one at a time, in a special way.\n",
        "\n",
        "When an iteration over a set of item starts using the for statement, the generator is run. Once the generator's function code reaches a \"yield\" statement, the generator yields its execution back to the for loop, returning a new value from the set. The generator function can generate as many values (possibly infinite) as it wants, yielding each one in its turn.\n",
        "\n",
        "You can write the following code to understand better the logic generator call uses:\n",
        "\n",
        "\n",
        "```\n",
        "import random\n",
        "\n",
        "def lottery():\n",
        "    # returns 6 numbers between 1 and 40\n",
        "    for i in range(6):\n",
        "        yield random.randint(1, 40)\n",
        "\n",
        "    # returns a 7th number between 1 and 15\n",
        "    yield random.randint(1,15)\n",
        "\n",
        "for random_number in lottery():\n",
        "       print(\"And the next number is... %d!\" %(random_number))\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeboN4B93BTi",
        "colab_type": "code",
        "outputId": "fb0e1d63-39ce-46b2-ebab-2c13d3884e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use generators since we might not be able to fit all the images into memory.\n",
        "train_generator = image_data.flow_from_directory(\n",
        "    trainer_dir,\n",
        "    subset='training',\n",
        "    color_mode='grayscale',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary', #the model is binary since we have just 2 classes - bad or good\n",
        "    classes=class_labels\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 320 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX-ZGnja3CQT",
        "colab_type": "code",
        "outputId": "da20fb6d-cf92-4266-8087-c1385a6e517a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valid_generator = image_data.flow_from_directory(\n",
        "    trainer_dir,\n",
        "    subset='validation',\n",
        "    color_mode='grayscale',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    classes=class_labels\n",
        ")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CqxvShELgk3",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model training\n",
        "\n",
        "As you will see we use <font color=orange>ReLU</font> activation function in our model. ReLU stands for *rectified linear unit* Mathematically, it is defined as $f(x_i) = max(0, x_i)$. \n",
        "\n",
        "Visually, it looks like the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5AcJ1i1MA7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4eb9c3c4-8801-4764-cba6-975911d2af13"
      },
      "source": [
        " from IPython.display import Image\n",
        " Image(url= \"https://miro.medium.com/max/1026/1*DfMRHwxY1gyyDmrIAd-gjQ.png\", width=400, height=200)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/1026/1*DfMRHwxY1gyyDmrIAd-gjQ.png\" width=\"400\" height=\"200\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7FozNu7MFns",
        "colab_type": "text"
      },
      "source": [
        "ReLU is the most commonly used activation function in neural networks, especially in [CNNs](https://www.youtube.com/watch?v=YRhxdVk_sIs). \n",
        "\n",
        "If you are unsure what activation function to use in your network, ReLU is usually a good first choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HCh3qge3EBI",
        "colab_type": "code",
        "outputId": "3ee0fdd2-9d42-461c-8ba4-b821f0092c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "# Notice that images are grayscaled, therefore we have to set the number of channels to 1.\n",
        "# Image shape is `(width, height, num_channels)` in TensorFlow.\n",
        "in_shape = IMAGE_SIZE + (1,)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(3, (3,3), activation='relu', input_shape=in_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 3)       30        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 99, 99, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 99, 99, 3)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 29403)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 29404     \n",
            "=================================================================\n",
            "Total params: 29,434\n",
            "Trainable params: 29,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmplUgdo3HKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup some useful callbacks.\n",
        "visualizer = TensorBoard(log_dir='/tmp/layouts')\n",
        "checkpoint = ModelCheckpoint('{}-best.h5'.format(dataset_dir), monitor='val_acc', mode='max', save_best_only=True)\n",
        "earlystops = EarlyStopping(patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuIZMIO03JFL",
        "colab_type": "code",
        "outputId": "fa7f7dbf-708c-461a-b869-56aa851ec455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model.\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[visualizer, checkpoint, earlystops]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/5 [=================>............] - ETA: 2s - loss: 247.4128 - acc: 0.4896Epoch 1/100\n",
            "5/5 [==============================] - 5s 1s/step - loss: 211.4596 - acc: 0.4688 - val_loss: 321.6348 - val_acc: 0.4688\n",
            "Epoch 2/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 224.3815 - acc: 0.5078Epoch 1/100\n",
            "5/5 [==============================] - 3s 595ms/step - loss: 181.8356 - acc: 0.5344 - val_loss: 82.6008 - val_acc: 0.5312\n",
            "Epoch 3/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 114.3821 - acc: 0.5078Epoch 1/100\n",
            "5/5 [==============================] - 3s 614ms/step - loss: 110.2843 - acc: 0.5000 - val_loss: 47.4562 - val_acc: 0.5312\n",
            "Epoch 4/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 32.7841 - acc: 0.5664Epoch 1/100\n",
            "5/5 [==============================] - 3s 614ms/step - loss: 38.2964 - acc: 0.5281 - val_loss: 50.9043 - val_acc: 0.4688\n",
            "Epoch 5/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 22.5908 - acc: 0.6016Epoch 1/100\n",
            "5/5 [==============================] - 3s 627ms/step - loss: 18.5924 - acc: 0.6531 - val_loss: 12.9848 - val_acc: 0.5625\n",
            "Epoch 6/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 13.9728 - acc: 0.6211Epoch 1/100\n",
            "5/5 [==============================] - 3s 600ms/step - loss: 16.4312 - acc: 0.5781 - val_loss: 21.8360 - val_acc: 0.5625\n",
            "Epoch 7/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 14.2568 - acc: 0.6055Epoch 1/100\n",
            "5/5 [==============================] - 3s 622ms/step - loss: 13.1044 - acc: 0.6250 - val_loss: 6.6347 - val_acc: 0.7969\n",
            "Epoch 8/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 3.5663 - acc: 0.8320Epoch 1/100\n",
            "5/5 [==============================] - 3s 615ms/step - loss: 3.4919 - acc: 0.8250 - val_loss: 8.5035 - val_acc: 0.7188\n",
            "Epoch 9/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 4.7282 - acc: 0.8164Epoch 1/100\n",
            "5/5 [==============================] - 3s 615ms/step - loss: 4.7504 - acc: 0.8125 - val_loss: 2.8575 - val_acc: 0.7969\n",
            "Epoch 10/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 3.3799 - acc: 0.8711Epoch 1/100\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 3.1872 - acc: 0.8594 - val_loss: 4.3292 - val_acc: 0.7344\n",
            "Epoch 11/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 3.8414 - acc: 0.8008Epoch 1/100\n",
            "5/5 [==============================] - 3s 622ms/step - loss: 3.7320 - acc: 0.8094 - val_loss: 3.7191 - val_acc: 0.7500\n",
            "Epoch 12/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.2705 - acc: 0.8672Epoch 1/100\n",
            "5/5 [==============================] - 3s 623ms/step - loss: 2.3972 - acc: 0.8719 - val_loss: 3.1192 - val_acc: 0.7500\n",
            "Epoch 13/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.3414 - acc: 0.9023Epoch 1/100\n",
            "5/5 [==============================] - 3s 642ms/step - loss: 1.6342 - acc: 0.8969 - val_loss: 3.0425 - val_acc: 0.8594\n",
            "Epoch 14/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.3334 - acc: 0.8672Epoch 1/100\n",
            "5/5 [==============================] - 3s 622ms/step - loss: 2.0571 - acc: 0.8813 - val_loss: 1.6491 - val_acc: 0.8906\n",
            "Epoch 15/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.6787 - acc: 0.8906Epoch 1/100\n",
            "5/5 [==============================] - 3s 615ms/step - loss: 2.4406 - acc: 0.8938 - val_loss: 2.5072 - val_acc: 0.7969\n",
            "Epoch 16/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.1576 - acc: 0.8867Epoch 1/100\n",
            "5/5 [==============================] - 3s 594ms/step - loss: 2.1968 - acc: 0.8813 - val_loss: 4.6688 - val_acc: 0.8125\n",
            "Epoch 17/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.2729 - acc: 0.8828Epoch 1/100\n",
            "5/5 [==============================] - 3s 621ms/step - loss: 2.2020 - acc: 0.8813 - val_loss: 1.9471 - val_acc: 0.8281\n",
            "Epoch 18/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.7487 - acc: 0.8828Epoch 1/100\n",
            "5/5 [==============================] - 3s 621ms/step - loss: 1.8718 - acc: 0.8719 - val_loss: 2.0838 - val_acc: 0.8281\n",
            "Epoch 19/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.6621 - acc: 0.8672Epoch 1/100\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 2.5350 - acc: 0.8750 - val_loss: 2.6687 - val_acc: 0.8125\n",
            "Epoch 20/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.6711 - acc: 0.8867Epoch 1/100\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 2.3376 - acc: 0.9000 - val_loss: 4.2904 - val_acc: 0.7344\n",
            "Epoch 21/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.5399 - acc: 0.8945Epoch 1/100\n",
            "5/5 [==============================] - 3s 621ms/step - loss: 1.9461 - acc: 0.8875 - val_loss: 2.4482 - val_acc: 0.8438\n",
            "Epoch 22/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.0779 - acc: 0.8750Epoch 1/100\n",
            "5/5 [==============================] - 3s 649ms/step - loss: 2.3264 - acc: 0.8750 - val_loss: 1.3531 - val_acc: 0.8750\n",
            "Epoch 23/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.2709 - acc: 0.8984Epoch 1/100\n",
            "5/5 [==============================] - 3s 616ms/step - loss: 2.0514 - acc: 0.8969 - val_loss: 2.8635 - val_acc: 0.8125\n",
            "Epoch 24/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.2639 - acc: 0.9258Epoch 1/100\n",
            "5/5 [==============================] - 3s 600ms/step - loss: 1.1709 - acc: 0.9281 - val_loss: 3.1455 - val_acc: 0.8125\n",
            "Epoch 25/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.1056 - acc: 0.9219Epoch 1/100\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 1.5276 - acc: 0.9031 - val_loss: 1.9603 - val_acc: 0.8594\n",
            "Epoch 26/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.0016 - acc: 0.9258Epoch 1/100\n",
            "5/5 [==============================] - 3s 613ms/step - loss: 1.1964 - acc: 0.9281 - val_loss: 4.2582 - val_acc: 0.7812\n",
            "Epoch 27/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.8348 - acc: 0.9570Epoch 1/100\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 1.0835 - acc: 0.9406 - val_loss: 3.1914 - val_acc: 0.7812\n",
            "Epoch 28/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.9328 - acc: 0.9062Epoch 1/100\n",
            "5/5 [==============================] - 3s 638ms/step - loss: 1.9374 - acc: 0.8969 - val_loss: 3.0831 - val_acc: 0.7812\n",
            "Epoch 29/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.0850 - acc: 0.9336Epoch 1/100\n",
            "5/5 [==============================] - 3s 590ms/step - loss: 0.9967 - acc: 0.9375 - val_loss: 3.0489 - val_acc: 0.8438\n",
            "Epoch 30/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.7320 - acc: 0.9023Epoch 1/100\n",
            "5/5 [==============================] - 3s 612ms/step - loss: 1.5676 - acc: 0.9000 - val_loss: 1.7115 - val_acc: 0.8594\n",
            "Epoch 31/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.9131 - acc: 0.8633Epoch 1/100\n",
            "5/5 [==============================] - 3s 621ms/step - loss: 2.5278 - acc: 0.8750 - val_loss: 2.9732 - val_acc: 0.7969\n",
            "Epoch 32/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.7209 - acc: 0.9062Epoch 1/100\n",
            "5/5 [==============================] - 3s 645ms/step - loss: 1.7636 - acc: 0.9031 - val_loss: 2.4423 - val_acc: 0.7812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9453127438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDJcaUx23LCQ",
        "colab_type": "code",
        "outputId": "c1c10793-fa73-4e30-84a3-b06105566d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Report score from last epoch.\n",
        "loss, acc = model.evaluate_generator(valid_generator)\n",
        "print('Accuracy: {:.2f}%'.format(acc*100))\n",
        "\n",
        "# Finally save the model.\n",
        "model.save('{}.h5'.format(dataset_dir))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REp-E996NPrh",
        "colab_type": "text"
      },
      "source": [
        "As you can see our model showed a very good result reaching the accuracy of 85%. \n",
        "\n",
        "Now, we use our model to make predictions on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dAjiwmdOkSi",
        "colab_type": "text"
      },
      "source": [
        "## 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMUmunHR3V-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUOWl66S3uH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f872b229-965f-499a-8411-83954db4d5f2"
      },
      "source": [
        "dataset_dir = 'layouts-easy'\n",
        "trainer_dir = dataset_dir + '/train'\n",
        "\n",
        "# Specify manually the class labels, otherwise Keras will assign alphanumeric values\n",
        "# as directories are listed (in no particular order).\n",
        "dirname, class_labels, _ = next(os.walk(trainer_dir))\n",
        "print('Class labels: {}'.format(class_labels))\n",
        "\n",
        "# Don't compile the model when testing new data.\n",
        "# model = load_model('{}.h5'.format(dataset_dir), compile=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class labels: ['Good', 'Bad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRIRYY553yON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('{}.h5'.format(dataset_dir), compile=False) #compile the trained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATPROxXA3yvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68aa27e5-5505-4b9b-aab0-19a627ec9469"
      },
      "source": [
        "# Don't shuffle the data, so that we can get the groundtruth labels later.\n",
        "test_generator = ImageDataGenerator().flow_from_directory(\n",
        "    dataset_dir + '/test',\n",
        "    shuffle=False,\n",
        "    color_mode='grayscale',\n",
        "    target_size=(200, 200),\n",
        "    class_mode='binary',\n",
        "    classes=class_labels\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0yA5kR832v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since we have groundtruth labels, we can use `model.evaluate_generator` here.\n",
        "# However in production we don't have groundtruth so let's use the model to predict new data\n",
        "# and then compare the predictions against the test labels.\n",
        "y_true = list(map(lambda f : os.path.dirname(f), test_generator.filenames))\n",
        "probas = model.predict_generator(test_generator)\n",
        "y_pred = list(map(lambda p : class_labels[0] if p < 0.5 else class_labels[1], probas))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxzEMrMQ346L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d359aa13-c8f5-4700-8340-f25e4b1c3fa6"
      },
      "source": [
        "# Let's see how good those predictions were.\n",
        "precision, recall, fmeasure, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_labels, average='weighted')\n",
        "print('Precision: {:.2f}%'.format(precision * 100))\n",
        "print('Recall: {:.2f}%'.format(recall * 100))\n",
        "print('F-measure: {:.2f}%'.format(fmeasure * 100))\n",
        "\n",
        "# Finally compute the ROC AUC to see the discriminative power of the model.\n",
        "# We'll use the `roc_auc_score()` function, which expects *binary* groundtruth labels and probability estimates of the *positive class*;\n",
        "# so be careful how labels and probabilities are defined.\n",
        "binary_labels = [p == y_true[i] for i, p in enumerate(y_pred)]\n",
        "auc = roc_auc_score(binary_labels, 1 - probas, average='weighted')\n",
        "print('AUC: {:.2f}%'.format(auc * 100))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 82.79%\n",
            "Recall: 79.00%\n",
            "F-measure: 78.38%\n",
            "AUC: 64.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMM4UvANPsrO",
        "colab_type": "text"
      },
      "source": [
        "The final model ended up with accuracy 82.79%, good job!👍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5eD7PnX6Z9P",
        "colab_type": "text"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "Now, you know:\n",
        "\n",
        "1.   how important layout compositions\n",
        "2.   what is data augmentation\n",
        "3.   what is a generator function in Python\n",
        "4.   how to apply a simple sequential model\n",
        "5.   what is a ReLU activation function\n",
        "\n",
        "Do not hesitate to ask questions at otorrent@mail.ru\n",
        "\n",
        "Thank you for your attention and see you next exercise session!"
      ]
    }
  ]
}